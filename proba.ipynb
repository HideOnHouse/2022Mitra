{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FlowDataset(train=True)\n",
    "dataset_valid = FlowDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = dataset_train.get_xy()\n",
    "x_valid, y_valid = dataset_valid.get_xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_jobs=-1, random_state=GLOBAL_SEED, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:46:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=755,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    190273\n",
      "           1       0.99      1.00      0.99    135287\n",
      "\n",
      "    accuracy                           0.99    325560\n",
      "   macro avg       0.99      0.99      0.99    325560\n",
      "weighted avg       0.99      0.99      0.99    325560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detect_result(model, df:pd.DataFrame, x:np.array, threshold:int=0, scaler=None):\n",
    "    pred = model.predict_proba(x)\n",
    "    assert len(pred) == len(x)\n",
    "    total = set(df['dst_ip'])\n",
    "    candidate = df[pred >= 0.995].groupby('dst_ip')['dst_ip'].count()\n",
    "    detected = set(candidate[candidate >= threshold].index)\n",
    "    not_detected = total - detected\n",
    "    return detected, not_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detect_report(detected, not_detected, mal_ip, ben_ip, digit=4, verbose=False):\n",
    "    detected, not_detected = map(set, [detected, not_detected])\n",
    "    mal_ip, ben_ip = map(set, [mal_ip, ben_ip])\n",
    "    tp = detected & mal_ip\n",
    "    fp = detected & ben_ip\n",
    "    tn = not_detected & ben_ip\n",
    "    fn = not_detected & mal_ip\n",
    "    tp, fp, tn, fn = map(len, [tp, fp, tn, fn])\n",
    "    total = tp + fp + tn + fn\n",
    "    acc = (tp + tn) / total\n",
    "    pre = (tp) / (tp + fp + 1e-8)\n",
    "    rec = (tp) / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (pre * rec) / (pre + rec + 1e-8)\n",
    "    if verbose:\n",
    "        print(f\"accuracy: {acc:.{digit}}\\nprecision: {pre:.{digit}}\\nrecall: {rec:.{digit}}\\nf1: {f1:.{digit}}\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected, not_detected = get_detect_result(model, dataset_valid.df, x_valid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5826210782217982"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_detect_report(detected, not_detected, dataset_valid.outer_mal, dataset_valid.outer_ben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_valid.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prob_0'] = pred[:, 0]\n",
    "df['prob_1'] = pred[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = df.groupby('dst_ip', as_index=False)[['prob_0', 'prob_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0830a2fe402f451cac368f70add33b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.990449\n",
      "precision: 0.980645\n",
      "recall: 0.997812\n",
      "f1: 0.989154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9891540079941042"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = raw.mean()\n",
    "whole = set(temp['dst_ip'])\n",
    "best_f1, best_threshold = 0, 0\n",
    "best_detected, best_not_detected = None, None\n",
    "for i in tqdm(np.linspace(0, 1, 1000)):\n",
    "    detected = set(temp[temp['prob_1'] >= i]['dst_ip'])\n",
    "    not_detected = whole - detected\n",
    "    t = get_detect_report(detected, not_detected, dataset_valid.outer_mal, dataset_valid.outer_ben)\n",
    "    if t > best_f1:\n",
    "        best_threshold = i\n",
    "        best_f1 = t\n",
    "        best_detected = detected\n",
    "        best_not_detected = not_detected\n",
    "get_detect_report(best_detected, best_not_detected, dataset_valid.outer_mal, dataset_valid.outer_ben, digit=6, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6085608560856086"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proba_best_detected.pkl', 'wb') as f:\n",
    "    pickle.dump(best_detected, f)\n",
    "with open('proba_best_not_detected.pkl', 'wb') as f:\n",
    "    pickle.dump(best_not_detected, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('one')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "601a5df23d8ad33032c3f7df0ea1a94b78932dde0ba49536eb81521cb801a817"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
